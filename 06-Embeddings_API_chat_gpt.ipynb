{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Linear algebra utilities\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Text preprocessing\n",
    "import unidecode\n",
    "import nltk\n",
    "# nltk.download('stopwords')  # Uncomment this if stopwords are not downloaded yet\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Parquet file handling\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Machine learning and embeddings\n",
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "import torch\n",
    "\n",
    "# Progress bar utility\n",
    "from tqdm import tqdm\n",
    "\n",
    "# OpenAI API (if needed later in your pipeline)\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned OpenStreetMap (OSM) categories dataset\n",
    "df_osm = pd.read_csv('Database/Clean_categories/categories_OSM_clean.csv', sep=';')\n",
    "\n",
    "# Load the cleaned Foursquare (FS) categories dataset\n",
    "df_fs = pd.read_csv('Database/Clean_categories/categories_FS_clean.csv', sep=';')\n",
    "\n",
    "# Load the Foursquare categories dataset with additional textual descriptions\n",
    "df_fs_desc = pd.read_csv('Database/Clean_categories/categories_FS_clean_description.csv', sep=';')\n",
    "\n",
    "# Load the \"oracle\" dataset, probably used as ground truth or reference mapping\n",
    "df_oracle = pd.read_csv('df_oracle.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310df527",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda4d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of English stopwords from NLTK\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text fields\n",
    "def clean_text(text):\n",
    "    if text is None or pd.isna(text):  # keep None or NaN values unchanged\n",
    "        return None\n",
    "    \n",
    "    text = str(text).lower()                        # convert to lowercase\n",
    "    text = unidecode.unidecode(text)                # remove accents/diacritics\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)             # remove punctuation\n",
    "    words = text.split()                            # split into individual words\n",
    "    words = [word for word in words if word not in stop_words]  # remove stopwords\n",
    "    return ' '.join(words)                          # join words back into a string\n",
    "\n",
    "# Apply text cleaning to OSM dataset\n",
    "df_oracle['OSM_tag'] = df_oracle['OSM_tag'].apply(clean_text)\n",
    "df_oracle['FS_tag'] = df_oracle['FS_tag'].apply(clean_text)\n",
    "\n",
    "df_osm['Tag'] = df_osm['Tag'].apply(clean_text)\n",
    "df_osm['token_Description'] = df_osm['Description'].apply(clean_text)\n",
    "df_osm['Depth_1'] = df_osm['Depth_1'].apply(clean_text)\n",
    "df_osm['Depth_2'] = df_osm['Depth_2'].apply(clean_text)\n",
    "df_osm['Depth_3'] = df_osm['Depth_3'].apply(clean_text)\n",
    "\n",
    "# Apply text cleaning to Foursquare dataset\n",
    "df_fs['Tag'] = df_fs['Tag'].apply(clean_text)\n",
    "df_fs['Depth_1'] = df_fs['Depth_1'].apply(clean_text)\n",
    "df_fs['Depth_2'] = df_fs['Depth_2'].apply(clean_text)\n",
    "df_fs['Depth_3'] = df_fs['Depth_3'].apply(clean_text)\n",
    "df_fs['Depth_4'] = df_fs['Depth_4'].apply(clean_text)\n",
    "df_fs['Depth_5'] = df_fs['Depth_5'].apply(clean_text)\n",
    "df_fs['Depth_6'] = df_fs['Depth_6'].apply(clean_text)\n",
    "\n",
    "# Apply text cleaning to Foursquare dataset with descriptions\n",
    "df_fs_desc['Tag'] = df_fs_desc['Tag'].apply(clean_text)\n",
    "df_fs_desc['Depth_1'] = df_fs_desc['Depth_1'].apply(clean_text)\n",
    "df_fs_desc['Depth_2'] = df_fs_desc['Depth_2'].apply(clean_text)\n",
    "df_fs_desc['Depth_3'] = df_fs_desc['Depth_3'].apply(clean_text)\n",
    "df_fs_desc['Depth_4'] = df_fs_desc['Depth_4'].apply(clean_text)\n",
    "df_fs_desc['Depth_5'] = df_fs_desc['Depth_5'].apply(clean_text)\n",
    "df_fs_desc['Depth_6'] = df_fs_desc['Depth_6'].apply(clean_text)\n",
    "df_fs_desc = df_fs_desc.rename(columns={\"definition_en\": \"Description\"})  # rename column for clarity\n",
    "df_fs_desc['token_Description'] = df_fs_desc['Description'].apply(clean_text)\n",
    "\n",
    "# Create cleaned versions of the datasets for later use\n",
    "df_osm_clean = df_osm\n",
    "df_fs_clean = df_fs\n",
    "df_fs_desc_clean = df_fs_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create in each dataset a column that contains all the information about the POI\n",
    "def concat_columns_osm(row):\n",
    "    parts = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3', 'token_Description']:\n",
    "        val = row[col]\n",
    "        if val is not None and pd.notna(val):  # Ignore None and NaN values\n",
    "            parts.append(str(val))\n",
    "    return ' '.join(parts)\n",
    "\n",
    "def concat_columns_fs(row):\n",
    "    parts = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3', 'Depth_4', \"Depth_5\", \"Depth_6\"]:\n",
    "        val = row[col]\n",
    "        if val is not None and pd.notna(val):  # Ignore None and NaN values\n",
    "            parts.append(str(val))\n",
    "    return ' '.join(parts)\n",
    "\n",
    "def concat_columns_fs_desc(row):\n",
    "    parts = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3', 'Depth_4', \"Depth_5\", \"Depth_6\", \"token_Description\"]:\n",
    "        val = row[col]\n",
    "        if val is not None and pd.notna(val):  # Ignore None and NaN values\n",
    "            parts.append(str(val))\n",
    "    return ' '.join(parts)\n",
    "\n",
    "\n",
    "# Create new columns by concatenating multiple text fields into a single string\n",
    "df_osm['full_info'] = df_osm.apply(concat_columns_osm, axis=1)\n",
    "df_fs_desc['full_info_and_desc'] = df_fs_desc.apply(concat_columns_fs_desc, axis=1)\n",
    "df_fs_desc['full_info'] = df_fs_desc.apply(concat_columns_fs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# we create a column in each dataset that contains the path of the POI in the categorization\n",
    "def concat_depths_osm(row):\n",
    "    levels = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3']:\n",
    "        val = row[col]\n",
    "        if pd.notna(val) and val is not None and str(val).strip() != '':\n",
    "            levels.append(str(val).strip())\n",
    "    return ' > '.join(levels)\n",
    "\n",
    "df_osm['Path'] = df_osm.apply(concat_depths_osm, axis=1)\n",
    "\n",
    "def concat_depths_fs(row):\n",
    "    levels = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3', 'Depth_4', \"Depth_5\", \"Depth_6\"]:\n",
    "        val = row[col]\n",
    "        if pd.notna(val) and val is not None and str(val).strip() != '':\n",
    "            levels.append(str(val).strip())\n",
    "    return ' > '.join(levels)\n",
    "\n",
    "#df_fs['Path'] = df_fs.apply(concat_depths_fs, axis=1)  # optional, commented out\n",
    "df_fs_desc['Path'] = df_fs_desc.apply(concat_depths_fs, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Remove duplicate words while keeping order (convert to dict keys then join)\n",
    "df_fs_desc[\"full_info_and_desc_set\"] = df_fs_desc[\"full_info_and_desc\"].apply(\n",
    "    lambda x: \" \".join(dict.fromkeys(x.split()))\n",
    ")\n",
    "\n",
    "df_osm[\"full_info_set\"] = df_osm[\"full_info\"].apply(\n",
    "    lambda x: \" \".join(dict.fromkeys(x.split()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd19b9",
   "metadata": {},
   "source": [
    "# ChatGPT as a final chooser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text fields\n",
    "def clean_text(text):\n",
    "    if text is None or pd.isna(text):  # keep None or NaN as they are\n",
    "        return None\n",
    "    \n",
    "    text = str(text).lower()                        # convert to lowercase\n",
    "    text = unidecode.unidecode(text)                # remove accents\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)             # remove punctuation\n",
    "    words = text.split()                            # split into words\n",
    "    words = [word for word in words if word not in stop_words]  # remove stopwords\n",
    "    return ' '.join(words)                          # rejoin into cleaned string\n",
    "\n",
    "# Apply text cleaning to Foursquare dataset columns\n",
    "df_fs['Tag'] = df_fs['Tag'].apply(clean_text)\n",
    "df_fs['Depth_1'] = df_fs['Depth_1'].apply(clean_text)\n",
    "df_fs['Depth_2'] = df_fs['Depth_2'].apply(clean_text)\n",
    "df_fs['Depth_3'] = df_fs['Depth_3'].apply(clean_text)\n",
    "df_fs['Depth_4'] = df_fs['Depth_4'].apply(clean_text)\n",
    "df_fs['Depth_5'] = df_fs['Depth_5'].apply(clean_text)\n",
    "df_fs['Depth_6'] = df_fs['Depth_6'].apply(clean_text)\n",
    "\n",
    "# Function to concatenate hierarchical depth columns into a single path string\n",
    "def concat_depths_fs(row):\n",
    "    levels = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3', 'Depth_4', \"Depth_5\", \"Depth_6\"]:\n",
    "        val = row[col]\n",
    "        if pd.notna(val) and val is not None and str(val).strip() != '':\n",
    "            levels.append(str(val).strip())\n",
    "    return ' > '.join(levels)\n",
    "\n",
    "# Add a new column with the full category path of each tag\n",
    "df_fs['Path'] = df_fs.apply(concat_depths_fs, axis=1)\n",
    "\n",
    "# Build a dictionary mapping: tag -> full path\n",
    "tag_to_path = dict(zip(df_fs[\"Tag\"], df_fs[\"Path\"]))\n",
    "\n",
    "# Build a dictionary mapping: tag -> main category (Depth_1)\n",
    "tag_to_main = dict(zip(df_fs[\"Tag\"], df_fs[\"Depth_1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2ee4c9",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=\"your_api_key\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # fast model\n",
    "\n",
    "def make_matchs(model, model_name, description_osm, description_fs, df_osm, df_fs_desc, desc_fs=\"\", k=5):\n",
    "    model.similarity_fn_name = SimilarityFunction.COSINE  \n",
    "    \n",
    "    # Compute embeddings for OSM descriptions\n",
    "    print(\"-- beginning embedding OSM\")\n",
    "    embeddings_1 = model.encode(description_osm, convert_to_tensor=True) \n",
    "    print(\"-- end embedding OSM\")\n",
    "\n",
    "    # Compute embeddings for FS descriptions\n",
    "    print(\"-- beginning embedding FS\")\n",
    "    embeddings_2 = model.encode(description_fs, convert_to_tensor=True) \n",
    "    print(\"-- end embedding FS\")\n",
    "\n",
    "    # Cosine similarity between OSM and FS embeddings\n",
    "    similarity_score = model.similarity(embeddings_1, embeddings_2)\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Iterate through OSM categories\n",
    "    for idx1, row1 in df_osm.iterrows():\n",
    "        # Get top-k indices and similarity scores for each OSM entry\n",
    "        topk_scores, topk_indices = torch.topk(similarity_score[idx1], k)\n",
    "\n",
    "        # Extract FS tags and corresponding scores\n",
    "        topk_tags = df_fs_desc.iloc[topk_indices.tolist()]['Tag'].tolist()\n",
    "        topk_scores = topk_scores.tolist()\n",
    "        \n",
    "        # Store match information\n",
    "        matches.append({\n",
    "            'OSM_tag': row1['Tag'],\n",
    "            'OSM_description': row1['Description'],\n",
    "            'OSM_main': row1[\"Depth_1\"],\n",
    "            'OSM_path': row1['Path'],\n",
    "            'FS_topk_tags': topk_tags,\n",
    "            'FS_topk_scores': topk_scores\n",
    "        })\n",
    "\n",
    "    # Helper to get FS paths for top-k tags\n",
    "    def get_paths(topk_tags):\n",
    "            return [tag_to_path.get(tag, None) for tag in topk_tags]\n",
    "    \n",
    "    # Helper to get FS main categories for top-k tags\n",
    "    def get_main(topk_tags):\n",
    "            return [tag_to_main.get(tag, None) for tag in topk_tags]\n",
    "\n",
    "    # Convert matches to DataFrame and enrich with paths and main categories\n",
    "    matches_df = pd.DataFrame(matches)\n",
    "    matches_df['FS_topk_paths'] = matches_df['FS_topk_tags'].apply(get_paths)\n",
    "    matches_df[\"FS_topk_main\"] = matches_df[\"FS_topk_tags\"].apply(get_main)\n",
    "    \n",
    "    return matches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e15e2",
   "metadata": {},
   "source": [
    "## Different ChatGPT prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781ac16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt_to_choose_prompt_2(osm_tag, osm_path, osm_desc, candidates, k):\n",
    "    # Construire le prompt avec règles supplémentaires\n",
    "    prompt = f\"\"\"\n",
    "    I want to map an OpenStreetMap (OSM) point of interest (POI) to the most appropriate FourSquare (FS) POI (tag).\n",
    "\n",
    "    Rules:\n",
    "    1. If an FS tag exactly matches the OSM tag (same name or clear synonym), choose that FS tag directly.\n",
    "    2. If no exact match exists, choose the FS tag that is the most specific and precise category in which the OSM tag could reasonably be classified.\n",
    "    - Do not just pick the most semantically similar.\n",
    "    - Prefer the FS tag that fully contains the concept of the OSM tag, even if its wording is broader.\n",
    "    3. Always answer with exactly one FS tag name from the provided list, nothing else.\n",
    "\n",
    "    OSM Tag: {osm_tag}  \n",
    "    OSM Tag Description: {osm_desc}  \n",
    "    OSM Tag Categorisation in OSM: {osm_path}  \n",
    "\n",
    "    Here are the {k} most relevant FS tags (with their descriptions):  \n",
    "    {candidates.to_string(index=False)}  \n",
    "\n",
    "    Question: Which FS tag best matches the OSM tag?  \n",
    "    Answer only with the FS tag name. \"\"\" \n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # rapide et pas cher\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb94cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt_to_choose_prompt_3(osm_tag, osm_path, osm_desc, candidates, k):\n",
    "    # Construire le prompt avec règles supplémentaires\n",
    "    prompt = f\"\"\"\n",
    "    I want to map an OpenStreetMap (OSM) point of interest (POI) to the most appropriate FourSquare (FS) POI (tag).\n",
    "\n",
    "    Rules:\n",
    "    1. If an FS tag exactly matches the OSM tag (same name or clear synonym), choose that FS tag directly.\n",
    "    2. If no exact match exists, choose the FS tag that is the most specific and precise category in which the OSM tag could reasonably be classified.\n",
    "    - Do not just pick the most semantically similar.\n",
    "    - Prefer the FS tag that fully contains the concept of the OSM tag, even if its wording is broader.\n",
    "    3. If none of the provided FS tags are a good fit, you may instead choose one category from the following broader fallback categories:\n",
    "    - landmarks outdoors\n",
    "    - business professional services\n",
    "    - travel transportation\n",
    "    - community government\n",
    "    - retail\n",
    "    - sports recreation\n",
    "    - health medicine\n",
    "    - arts entertainment\n",
    "    - dining drinking\n",
    "    - event\n",
    "    4. Always answer with exactly one FS tag name from the provided list or, if necessary, one fallback category, nothing else.\n",
    "\n",
    "\n",
    "    OSM Tag: {osm_tag}  \n",
    "    OSM Tag Description: {osm_desc}  \n",
    "    OSM Tag Categorisation in OSM: {osm_path}  \n",
    "\n",
    "    Here are the {k} most relevant FS tags (with their descriptions):  \n",
    "    {candidates.to_string(index=False)}  \n",
    "\n",
    "    Question: Which FS tag best matches the OSM tag?  \n",
    "    Answer only with the FS tag name. \"\"\" \n",
    "\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  #rapide et pas cher\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09171caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt_to_choose_prompt_5(osm_tag, osm_path, osm_desc, candidates, k):\n",
    "    prompt = f\"\"\"\n",
    "    I want to map an OpenStreetMap (OSM) point of interest (POI) to the most appropriate FourSquare (FS) POI (tag).\n",
    "\n",
    "    Rules:\n",
    "    1. If an FS tag exactly matches the OSM tag (same name or clear synonym), choose that FS tag directly.\n",
    "    2. If no exact match exists, select the FS tag that is the most precise parent category that fully contains the OSM tag.\n",
    "       - Do not just pick the most semantically similar wording.\n",
    "       - Prefer a broader FS tag that logically includes the OSM tag concept, even if it is less specific.\n",
    "       - Exclude FS tags that are related but do not actually contain the OSM concept.\n",
    "    3. Think step by step: first check for an exact match, then find the correct parent category.\n",
    "    4. Output only one FS tag name from the provided list. No explanations, no extra text.\n",
    "\n",
    "    Example:\n",
    "    OSM Tag: \"sea\"  \n",
    "    OSM Tag Description: \"A large body of salt water part of, or connected to, an ocean.\"  \n",
    "    OSM Tag Categorisation in OSM: \"place > sea\"  \n",
    "\n",
    "    FS Candidates:  \n",
    "    ['lake', 'bay', 'bathing area', 'dive spot', 'island', 'surf spot', 'waterfront', 'river', 'landmarks outdoors', 'boat launch']\n",
    "\n",
    "    Correct Answer: landmarks outdoors\n",
    "\n",
    "    Now, process the following case:\n",
    "\n",
    "    OSM Tag: {osm_tag}  \n",
    "    OSM Tag Description: {osm_desc}  \n",
    "    OSM Tag Categorisation in OSM: {osm_path}  \n",
    "\n",
    "    Here are the {k} most relevant FS tags (with their descriptions):  \n",
    "    {candidates.to_string(index=False)}  \n",
    "\n",
    "    Question: Which FS tag best matches the OSM tag?  \n",
    "    Answer only with the FS tag name.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # rapide et pas cher\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c09d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt_to_choose_prompt_6(osm_tag, osm_path, osm_desc, candidates, k):\n",
    "    prompt = f\"\"\"\n",
    "    I want to map an OpenStreetMap (OSM) point of interest (POI) to the most appropriate FourSquare (FS) POI (tag).\n",
    "\n",
    "    Rules:\n",
    "    1. If an FS tag exactly matches the OSM tag (same name or clear synonym), choose that FS tag directly.\n",
    "    2. If no exact match exists, select the FS tag that is the most precise parent category that fully contains the OSM tag.\n",
    "       - Do not just pick the most semantically similar wording.\n",
    "       - Prefer a broader FS tag that logically includes the OSM tag concept.\n",
    "       - Exclude FS tags that are related but do not actually contain the OSM concept.\n",
    "    3. If none of the {k} FS candidates are suitable, then choose from the following broader FS categories:\n",
    "       - landmarks outdoors\n",
    "       - business professional services\n",
    "       - travel transportation\n",
    "       - community government\n",
    "       - retail\n",
    "       - sports recreation\n",
    "       - health medicine\n",
    "       - arts entertainment\n",
    "       - dining drinking\n",
    "       - event\n",
    "    4. Think step by step: first check for an exact match, then find the correct parent category, and only if needed, fall back to the broader FS categories above.\n",
    "    5. Output only one FS tag name from the provided list (either from the {k} candidates or from the broader categories).\n",
    "       Do not add explanations, reasoning, or extra text.\n",
    "\n",
    "    Example:\n",
    "    OSM Tag: \"sea\"  \n",
    "    OSM Tag Description: \"A large body of salt water part of, or connected to, an ocean.\"  \n",
    "    OSM Tag Categorisation in OSM: \"place > sea\"  \n",
    "\n",
    "    FS Candidates:  \n",
    "    ['lake', 'bay', 'bathing area', 'dive spot', 'island', 'surf spot', 'waterfront', 'river', 'landmarks outdoors', 'boat launch']\n",
    "\n",
    "    Correct Answer: landmarks outdoors \n",
    "\n",
    "    Now, process the following case:\n",
    "\n",
    "    OSM Tag: {osm_tag}  \n",
    "    OSM Tag Description: {osm_desc}  \n",
    "    OSM Tag Categorisation in OSM: {osm_path}  \n",
    "\n",
    "    Here are the {k} most relevant FS tags (with their descriptions):  \n",
    "    {candidates.to_string(index=False)}  \n",
    "\n",
    "    Question: Which FS tag best matches the OSM tag?  \n",
    "    Answer only with the FS tag name.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # rapide et pas cher\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ffe704",
   "metadata": {},
   "source": [
    "## Choice by CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d9daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Select the prompts we want to test\n",
    "prompts = [2,3,5,6]\n",
    "# Choose the value of k\n",
    "k=20 # number of candidates to provide to ChatGPT\n",
    "\n",
    "def concat_depths_fs(row):\n",
    "    levels = []\n",
    "    for col in ['Depth_1', 'Depth_2', 'Depth_3', 'Depth_4', \"Depth_5\", \"Depth_6\"]:\n",
    "        val = row[col]\n",
    "        if pd.notna(val) and val is not None and str(val).strip() != '':\n",
    "            levels.append(str(val).strip())\n",
    "    return ' > '.join(levels)\n",
    "\n",
    "# Create a full path column by concatenating all depth levels\n",
    "df_fs['Path'] = df_fs.apply(concat_depths_fs, axis=1)\n",
    "\n",
    "# Build a dictionary mapping FS tag -> path\n",
    "tag_to_path = dict(zip(df_fs[\"Tag\"], df_fs[\"Path\"]))\n",
    "\n",
    "# Generate matches using the function make_matchs\n",
    "matches_df = make_matchs(\n",
    "    model=model,\n",
    "    model_name=\"MiniLM\",\n",
    "    description_osm=df_osm[\"full_info\"].tolist(),\n",
    "    description_fs=df_fs_desc[\"full_info_and_desc\"].tolist(),\n",
    "    df_osm=df_osm,\n",
    "    df_fs_desc=df_fs_desc,\n",
    "    k=k  \n",
    ")\n",
    "\n",
    "# Loop through each selected prompt\n",
    "for script in prompts:\n",
    "    k = k # or another value if needed\n",
    "    results = []\n",
    "\n",
    "    print(f\"--- Running prompt {script} ---\")\n",
    "\n",
    "    # Iterate through each row of the matches dataframe with a progress bar\n",
    "    for idx, row in tqdm(matches_df.iterrows(), total=len(matches_df)):\n",
    "        osm_tag = row[\"OSM_tag\"]\n",
    "        osm_desc = row[\"OSM_description\"]\n",
    "        osm_path = row[\"OSM_path\"]\n",
    "        fs_candidates = row[\"FS_topk_tags\"]\n",
    "        fs_path = row[\"FS_topk_paths\"]\n",
    "        fs_scores = row[\"FS_topk_scores\"]\n",
    "        fs_main = row[\"FS_topk_main\"]\n",
    "\n",
    "        # Temporary dataframe for the candidates of this prompt\n",
    "        candidates = pd.DataFrame({\n",
    "            \"FS_tag\": fs_candidates,\n",
    "            \"Score\": fs_scores\n",
    "        })\n",
    "\n",
    "        # Call the GPT API according to the prompt\n",
    "        if script == 2:\n",
    "            fs_choice = ask_gpt_to_choose_prompt_2(osm_tag, osm_path, osm_desc, candidates, k)\n",
    "        elif script == 3:\n",
    "            fs_choice = ask_gpt_to_choose_prompt_3(osm_tag, osm_path, osm_desc, candidates, k)\n",
    "        elif script == 5:\n",
    "            fs_choice = ask_gpt_to_choose_prompt_5(osm_tag, osm_path, osm_desc, candidates, k)\n",
    "        elif script == 6:\n",
    "            fs_choice = ask_gpt_to_choose_prompt_6(osm_tag, osm_path, osm_desc, candidates, k)\n",
    "        else :\n",
    "            print(\"PROBLEEEEEEEEEEM\")\n",
    "\n",
    "        # Store the results for this row\n",
    "        results.append({\n",
    "            \"OSM_tag\": osm_tag,\n",
    "            \"OSM_path\": osm_path,\n",
    "            \"OSM_description\": osm_desc,\n",
    "            \"FS_candidates\": fs_candidates,\n",
    "            \"FS_scores\": fs_scores,\n",
    "            \"FS_tag_GPT\": fs_choice\n",
    "        })\n",
    "\n",
    "    # Create the final dataframe for this prompt\n",
    "    df_gpt_mapping = pd.DataFrame(results)\n",
    "\n",
    "    # Merge with the oracle dataframe\n",
    "    df_oracle = pd.read_csv('df_oracle.csv', sep=\";\")\n",
    "    df_match = pd.merge(df_gpt_mapping, df_oracle, \n",
    "                        left_on=[\"OSM_tag\", \"OSM_path\"], \n",
    "                        right_on=['OSM_tag', \"OSM_path\"], how=\"left\")\n",
    "    df_match = df_match.rename(columns={\"FS_tag\":\"FS_manual_tag\"})\n",
    "\n",
    "    # Create a column indicating if the GPT prediction matches the manual FS tag\n",
    "    df_match[\"correct\"] = (df_match['FS_manual_tag'] == df_match['FS_tag_GPT']).astype(int)\n",
    "        \n",
    "    def is_new_correct(fs_manual_tag, fs_tag_gpt, tag_to_path):\n",
    "        # Condition 1: exact match\n",
    "        if fs_manual_tag == fs_tag_gpt:\n",
    "            return 1\n",
    "        # Condition 2: FS_manual_tag appears anywhere in the path of FS_tag_GPT\n",
    "        path_str = tag_to_path.get(fs_tag_gpt, \"\")  # get path as string\n",
    "        path_tags = [tag.strip() for tag in path_str.split(\">\")]  # split path into tags\n",
    "        if fs_manual_tag in path_tags:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    # Apply the function row by row to create a new_correct column\n",
    "    df_match[\"new_correct\"] = df_match.apply(\n",
    "        lambda row: is_new_correct(row[\"FS_manual_tag\"], row[\"FS_tag_GPT\"], tag_to_path),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Extract the main OSM category and the first two levels\n",
    "    df_match[\"OSM_main\"] = df_match[\"OSM_path\"].str.split(\" > \").str[0]\n",
    "    df_match[\"OSM_main_sub\"] = df_match[\"OSM_path\"].apply(lambda x: \" > \".join(x.split(\" > \")[:2]))\n",
    "\n",
    "    # Save the dataframe immediately after each prompt\n",
    "    filename = f\"FID gpt models/miniLM + chat_gpt_prompt_{script} (k={k}).csv\"\n",
    "    df_match.to_csv(filename, index=False, sep=\";\")\n",
    "    print(f\"✅ Prompt {script} completed and saved to {filename}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
